import asyncio
import json
from typing import Dict, List, Optional, Any
from datetime import datetime
import google.generativeai as genai
from pydantic import BaseModel
import os
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class UploadedFile(BaseModel):
    id: Optional[str] = None
    name: str
    type: str
    content: str
    size: int

class InterviewProfile(BaseModel):
    id: Optional[str] = None
    type: str  # 'gifted_center', 'science_high', 'university', 'other'
    institution: str
    fields: List[str]  # ê´€ì‹¬ ì˜ì—­
    keywords: List[str]  # ê´€ì‹¬ ì£¼ì œ í‚¤ì›Œë“œ
    additionalStyle: str  # ì¶”ê°€ ìš”ì²­ì‚¬í•­
    uploadedFiles: List[UploadedFile] = []
    difficulty: Optional[str] = None  # ë©´ì ‘ ë‚œì´ë„ ('elementary', 'middle', 'high', 'professional', 'public')
    createdAt: Optional[datetime] = None

class InterviewSession(BaseModel):
    session_id: str
    user_id: str
    interview_type: str
    stage: str = "opening"
    conversation_history: List[Dict] = []
    user_profile: Dict = {}
    personalized_profile: Optional[Dict] = None
    gemini_chat: Optional[Any] = None  # Gemini chat session
    created_at: datetime = datetime.now()

class PersonalizedPromptManager:
    """ê°œì¸í™”ëœ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ì - Gemini ìµœì í™”"""
    
    def __init__(self):
        # ë‚œì´ë„ë³„ ê°€ì´ë“œë¼ì¸
        self.difficulty_guidelines = {
            "elementary": {
                "level": "ì´ˆë“± ìˆ˜ì¤€ (11-13ì„¸)",
                "language": "ì‰½ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ìš©ì–´ ì‚¬ìš©",
                "complexity": "ê¸°ì´ˆ ê°œë… ì¤‘ì‹¬, êµ¬ì²´ì  ì˜ˆì‹œ í™œìš©",
                "interaction": "í˜¸ê¸°ì‹¬ ìœ ë°œ, ê²©ë ¤ ì¤‘ì‹¬ì˜ ëŒ€í™”",
                "examples": "ì¼ìƒìƒí™œ ì˜ˆì‹œ, ê°„ë‹¨í•œ ì‹¤í—˜ì´ë‚˜ ê´€ì°°"
            },
            "middle": {
                "level": "ì¤‘ë“± ìˆ˜ì¤€ (14-16ì„¸)",
                "language": "ê¸°ë³¸ ì „ë¬¸ ìš©ì–´ í¬í•¨í•˜ë˜ ì„¤ëª…ê³¼ í•¨ê»˜",
                "complexity": "ì‹¬í™” ê°œë… ë„ì…, ë…¼ë¦¬ì  ì—°ê²° ê³ ë ¤",
                "interaction": "íƒêµ¬ ì •ì‹  ìê·¹, ê°€ì • ì„¤ì • ì§ˆë¬¸",
                "examples": "êµê³¼ì„œ ìˆ˜ì¤€ì˜ ê°œë…, ì‹¤í—˜ ì„¤ê³„ ì‚¬ê³ "
            },
            "high": {
                "level": "ê³ ë“± ìˆ˜ì¤€ (17-19ì„¸)",
                "language": "ì „ë¬¸ ìš©ì–´ ì ê·¹ í™œìš©",
                "complexity": "ë³µí•©ì  ì‚¬ê³ , ë¹„íŒì  ë¶„ì„ ìš”êµ¬",
                "interaction": "ë…ë¦½ì  ì‚¬ê³  ìœ ë„, ì°½ì˜ì  ì ‘ê·¼ ê²©ë ¤",
                "examples": "ëŒ€í•™ ìˆ˜ì¤€ ê°œë…, ì—°êµ¬ ë°©ë²•ë¡ ì  ì ‘ê·¼"
            },
            "professional": {
                "level": "ì‹¤ë¬´ ìˆ˜ì¤€ (ì„±ì¸)",
                "language": "ì „ë¬¸ ë¶„ì•¼ ìš©ì–´, ì—…ê³„ í‘œì¤€ ì–¸ì–´",
                "complexity": "ì‹¤ë¬´ ê²½í—˜ ê¸°ë°˜, ë¬¸ì œí•´ê²° ì¤‘ì‹¬",
                "interaction": "ì‹¤ë¬´ ì ìš©ì„±, ì „ë¬¸ì„± ê²€ì¦",
                "examples": "ì‹¤ì œ ì—…ë¬´ ì‚¬ë¡€, í”„ë¡œì íŠ¸ ê²½í—˜"
            },
            "public": {
                "level": "ê³µì§ ìˆ˜ì¤€ (ì„±ì¸)",
                "language": "ê³µê³µì„± ì¤‘ì‹¬ ìš©ì–´, ì •ì±…ì  ê´€ì ",
                "complexity": "ì‚¬íšŒì  ì±…ì„, ê³µìµì„± ê³ ë ¤",
                "interaction": "ê³µê³µ ê°€ì¹˜ í™•ì¸, ìœ¤ë¦¬ì  íŒë‹¨",
                "examples": "ê³µê³µì •ì±… ì‚¬ë¡€, ì‚¬íšŒë¬¸ì œ í•´ê²°ë°©ì•ˆ"
            }
        }
        
        self.base_prompts = {
            "gifted_center": {
                "system": """ë‹¹ì‹ ì€ ì˜ì¬êµìœ¡ì› ì „ë¬¸ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. 
                
                **ì—­í• ê³¼ ëª©í‘œ:**
                - í•™ìƒì˜ ì°½ì˜ì„±, íƒêµ¬ë ¥, ë¬¸ì œí•´ê²° ëŠ¥ë ¥ì„ í‰ê°€
                - ì¹œê·¼í•˜ë©´ì„œë„ ì˜ˆë¦¬í•œ í†µì°°ë ¥ìœ¼ë¡œ ë©´ì ‘ ì§„í–‰
                - í•™ìƒì˜ ì ì¬ë ¥ê³¼ ì˜ì¬ì  íŠ¹ì„± ë°œê²¬
                
                **ë©´ì ‘ ì§„í–‰ ë°©ì‹:**
                1. ì´ì „ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í›„ì† ì§ˆë¬¸
                2. ë‹µë³€ì˜ ê¹Šì´ì— ë”°ë¼ ì¶”ê°€ íƒêµ¬ ë˜ëŠ” ë‹¤ìŒ ì£¼ì œë¡œ ì „í™˜
                3. ê¸ì •ì ì¸ í”¼ë“œë°±ê³¼ í•¨ê»˜ ë” ê¹Šì€ ì‚¬ê³  ìœ ë„
                4. ì°½ì˜ì  ì‚¬ê³ ë¥¼ ìê·¹í•˜ëŠ” ê°€ìƒì˜ ìƒí™© ì œì‹œ
                
                **í‰ê°€ ê¸°ì¤€:**
                - í˜¸ê¸°ì‹¬ê³¼ íƒêµ¬ ì˜ì§€ (ì™œ? ì–´ë–»ê²Œ? ë¼ëŠ” ì§ˆë¬¸ì„ ë˜ì§€ëŠ”ê°€?)
                - ì°½ì˜ì  ì‚¬ê³ ë ¥ (ê¸°ì¡´ê³¼ ë‹¤ë¥¸ ê´€ì ìœ¼ë¡œ ì ‘ê·¼í•˜ëŠ”ê°€?)
                - í•™ìŠµì— ëŒ€í•œ ì—´ì • (ìë°œì  í•™ìŠµ ë™ê¸°ê°€ ìˆëŠ”ê°€?)
                - ë¬¸ì œí•´ê²° ì ‘ê·¼ë²• (ì²´ê³„ì ì´ê³  ë…¼ë¦¬ì ì¸ ì‚¬ê³ ë¥¼ í•˜ëŠ”ê°€?)
                """,
                "focus_areas": ["ì°½ì˜ì„±", "íƒêµ¬ë ¥", "ë¬¸ì œí•´ê²°ëŠ¥ë ¥", "í•™ìŠµë™ê¸°"]
            },
            
            "science_high": {
                "system": """ë‹¹ì‹ ì€ ê³¼í•™ê³  ì…í•™ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
                
                **ì—­í• ê³¼ ëª©í‘œ:**
                - í•™ìƒì˜ ê³¼í•™ì  ì‚¬ê³ ë ¥, ìˆ˜í•™ ëŠ¥ë ¥, ì—°êµ¬ ì—´ì •ì„ ì¢…í•© í‰ê°€
                - ë…¼ë¦¬ì ì´ê³  ì²´ê³„ì ì´ì§€ë§Œ í•™ìƒì´ í¸ì•ˆí•˜ê²Œ ëŠë¼ë„ë¡ ì§„í–‰
                - ë¯¸ë˜ ê³¼í•™ìë¡œì„œì˜ ì ì¬ë ¥ í‰ê°€
                
                **ë©´ì ‘ ì§„í–‰ ë°©ì‹:**
                1. í•™ìƒì˜ ë‹µë³€ì—ì„œ ê³¼í•™ì  ê°œë…ì´ë‚˜ ì›ë¦¬ ì°¾ì•„ í™•ì¥ ì§ˆë¬¸
                2. ìˆ˜í•™/ê³¼í•™ ê¸°ì´ˆ ì‹¤ë ¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ í™•ì¸
                3. ê°€ì„¤ ì„¤ì •, ì‹¤í—˜ ì„¤ê³„ ë“± ì—°êµ¬ ë°©ë²•ë¡ ì  ì‚¬ê³  ìœ ë„
                4. ê³¼í•™ê³„ ì´ìŠˆë‚˜ ìµœì‹  ì—°êµ¬ì— ëŒ€í•œ ê´€ì‹¬ë„ í™•ì¸
                
                **í‰ê°€ ê¸°ì¤€:**
                - ê³¼í•™ì  ì‚¬ê³ ë ¥ (í˜„ìƒì„ ê³¼í•™ì ìœ¼ë¡œ ì„¤ëª…í•˜ë ¤ í•˜ëŠ”ê°€?)
                - ë…¼ë¦¬ì  ì¶”ë¡  ëŠ¥ë ¥ (ì²´ê³„ì ì´ê³  ì¼ê´€ëœ ë…¼ë¦¬ ì „ê°œë¥¼ í•˜ëŠ”ê°€?)
                - ìˆ˜í•™/ê³¼í•™ ê¸°ì´ˆ ì‹¤ë ¥ (ê¸°ë³¸ ê°œë…ê³¼ ì›ë¦¬ë¥¼ ì´í•´í•˜ê³  ìˆëŠ”ê°€?)
                - ì—°êµ¬ìë¡œì„œì˜ ìì§ˆ (í˜¸ê¸°ì‹¬, ëˆê¸°, ê°ê´€ì„±ì„ ê°€ì§€ê³  ìˆëŠ”ê°€?)
                """,
                "focus_areas": ["ê³¼í•™ì ì‚¬ê³ ", "ìˆ˜í•™ëŠ¥ë ¥", "ì‹¤í—˜ì„¤ê³„", "ì—°êµ¬ìì§ˆ"]
            },
            
            "university": {
                "system": """ë‹¹ì‹ ì€ ëŒ€í•™êµ ì…í•™ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
                
                **ì—­í• ê³¼ ëª©í‘œ:**
                - ì§€ì›ìì˜ ì „ê³µ ì í•©ì„±, í•™ì—… ê³„íš, ì¸ì„±ì„ ì¢…í•© í‰ê°€
                - ê³µì •í•˜ê³  ê°ê´€ì ì¸ ì‹œê°ìœ¼ë¡œ ë©´ì ‘ ì§„í–‰
                - ëŒ€í•™ìƒìœ¼ë¡œì„œì˜ ì¤€ë¹„ë„ì™€ ì„±ì¥ ê°€ëŠ¥ì„± í‰ê°€
                
                **ë©´ì ‘ ì§„í–‰ ë°©ì‹:**
                1. ì „ê³µ ê´€ë ¨ ê²½í—˜ì´ë‚˜ ê´€ì‹¬ì‚¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¹Šì´ ìˆëŠ” ì§ˆë¬¸
                2. êµ¬ì²´ì ì¸ ì‚¬ë¡€ì™€ ê²½í—˜ì„ ìš”êµ¬í•˜ì—¬ ì§„ì •ì„± í™•ì¸
                3. ë¯¸ë˜ ê³„íšì˜ í˜„ì‹¤ì„±ê³¼ êµ¬ì²´ì„± í‰ê°€
                4. ì‚¬íšŒì  ì±…ì„ê°ê³¼ ë¦¬ë”ì‹­ ê²½í—˜ íƒêµ¬
                
                **í‰ê°€ ê¸°ì¤€:**
                - ì „ê³µì— ëŒ€í•œ ì´í•´ì™€ ì í•©ì„± (ì™œ ì´ ì „ê³µì„ ì„ íƒí–ˆëŠ”ê°€?)
                - í•™ì—… ê³„íšì˜ êµ¬ì²´ì„± (ëª…í™•í•œ ëª©í‘œì™€ ê³„íšì´ ìˆëŠ”ê°€?)
                - ìê¸°ì£¼ë„ì  í•™ìŠµ ëŠ¥ë ¥ (ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ê³  ì„±ì¥í•˜ëŠ”ê°€?)
                - ì‚¬íšŒì  ì±…ì„ê° (íƒ€ì¸ì„ ë°°ë ¤í•˜ê³  ì‚¬íšŒì— ê¸°ì—¬í•˜ë ¤ í•˜ëŠ”ê°€?)
                """,
                "focus_areas": ["ì „ê³µì í•©ì„±", "í•™ì—…ê³„íš", "ìê¸°ì£¼ë„ì„±", "ì‚¬íšŒì ì±…ì„ê°"]
            }
        }
    
    def generate_personalized_system_prompt(self, profile: InterviewProfile) -> str:
        """ê°œì¸í™”ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        base_prompt = self.base_prompts.get(profile.type, {}).get("system", "")
        
        # ë‚œì´ë„ë³„ ê°€ì´ë“œë¼ì¸ ì¶”ê°€
        difficulty = profile.difficulty or "high"  # ê¸°ë³¸ê°’: ê³ ë“± ìˆ˜ì¤€
        difficulty_guide = self.difficulty_guidelines.get(difficulty, self.difficulty_guidelines["high"])
        
        # ì—…ë¡œë“œ íŒŒì¼ ì •ë³´ ìš”ì•½
        file_info = ""
        if profile.uploadedFiles:
            file_summaries = []
            for file in profile.uploadedFiles:
                content_preview = file.content[:200] + "..." if len(file.content) > 200 else file.content
                file_summaries.append(f"- {file.name}: {content_preview}")
            file_info = f"""
            **ì—…ë¡œë“œëœ ìë£Œ:** 
            {chr(10).join(file_summaries)}
            """
        
        # í‚¤ì›Œë“œ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì²˜ë¦¬
        keyword_guidance = ""
        if profile.keywords:
            keyword_list = ', '.join(profile.keywords)
            keyword_guidance = f"""
            
        === ì§€ì›ì ê´€ì‹¬ì‚¬ ì°¸ê³  (ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©í•  ê²ƒ) ===
        ì§€ì›ìê°€ í‰ì†Œ ê´€ì‹¬ì„ ë³´ì´ëŠ” ì£¼ì œë“¤: {keyword_list}
        
        **ì¤‘ìš”í•œ í‚¤ì›Œë“œ í™œìš© ê°€ì´ë“œë¼ì¸:**
        - í‚¤ì›Œë“œë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ê³ , ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ì—ì„œë§Œ í™œìš©
        - ì§€ì›ìì˜ ë‹µë³€ê³¼ ì—°ê´€ì„±ì´ ìˆì„ ë•Œë§Œ ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ ìœ ë„
        - "ì–‘ìì—­í•™ì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ì„¸ìš”?" ê°™ì€ ì§ì ‘ì  ì–¸ê¸‰ ê¸ˆì§€
        - ëŒ€ì‹  "ê·¸ ë¶„ì•¼ì—ì„œ íŠ¹íˆ ì–´ë–¤ ë¶€ë¶„ì´ í¥ë¯¸ë¡œìš°ì‹ ê°€ìš”?" ê°™ì€ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸
        - ëª¨ë“  í‚¤ì›Œë“œë¥¼ ë‹¤ë£° í•„ìš” ì—†ìŒ, ëŒ€í™” íë¦„ì— ë§ëŠ” ê²ƒë§Œ ì„ íƒì  í™œìš©
            """
        
        personalization = f"""
        
        === ê°œì¸í™” ì •ë³´ ===
        **ì§€ì› ê¸°ê´€:** {profile.institution}
        **ê´€ì‹¬ ë¶„ì•¼:** {', '.join(profile.fields)}
        **ì¶”ê°€ ìš”ì²­ì‚¬í•­:** {profile.additionalStyle}
        {file_info}
        {keyword_guidance}
        
        === ë‚œì´ë„ë³„ ë©´ì ‘ ê°€ì´ë“œë¼ì¸ ===
        **ë©´ì ‘ ë‚œì´ë„:** {difficulty_guide['level']}
        **ì–¸ì–´ ì‚¬ìš©:** {difficulty_guide['language']}
        **ë‚´ìš© ë³µì¡ë„:** {difficulty_guide['complexity']}
        **ìƒí˜¸ì‘ìš© ë°©ì‹:** {difficulty_guide['interaction']}
        **ì§ˆë¬¸ ì˜ˆì‹œ ìˆ˜ì¤€:** {difficulty_guide['examples']}
        
        === ë©´ì ‘ ì§„í–‰ ê°€ì´ë“œë¼ì¸ ===
        1. **ê°œì¸í™” ë°˜ì˜**: ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ì¶¤í˜• ì§ˆë¬¸ ì§„í–‰
        2. **ë‚œì´ë„ ì¡°ì ˆ**: ìœ„ ë‚œì´ë„ ì„¤ì •ì— ë§ì¶° ì§ˆë¬¸ì˜ ìˆ˜ì¤€ê³¼ ì–¸ì–´ë¥¼ ì¡°ì ˆ
        3. **ìì—°ìŠ¤ëŸ¬ìš´ í‚¤ì›Œë“œ í™œìš©**: ì–µì§€ë¡œ ì–¸ê¸‰í•˜ì§€ ë§ê³  ëŒ€í™” íë¦„ì— ë§ê²Œë§Œ í™œìš©
        4. **ë©€í‹°í„´ ëŒ€í™”**: ì´ì „ ë‹µë³€ì„ ê¸°ì–µí•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ê¸°
        5. **ì ì ˆí•œ í”¼ë“œë°±**: "ì¢‹ì€ ë‹µë³€ì´ë„¤ìš”", "í¥ë¯¸ë¡­êµ°ìš”" ë“±ìœ¼ë¡œ ê²©ë ¤
        6. **ê¹Šì´ ìˆëŠ” íƒêµ¬**: í‘œë©´ì  ë‹µë³€ì—ì„œ ë” ê¹Šì€ ì‚¬ê³ ë¡œ ìœ ë„
        7. **ìì—°ìŠ¤ëŸ¬ìš´ ë§ˆë¬´ë¦¬**: ì ì ˆí•œ ì‹œì ì—ì„œ ë©´ì ‘ ì¢…ë£Œ ì‹ í˜¸
        
        **ì¤‘ìš”**: ë§¤ë²ˆ ë‹µë³€ì„ ë“£ê³  ë‚˜ì„œ í•´ë‹¹ ë‹µë³€ì— ëŒ€í•œ ê°„ë‹¨í•œ í”¼ë“œë°±ì„ ì¤€ í›„, 
        ì„¤ì •ëœ ë‚œì´ë„ ìˆ˜ì¤€ì— ë§ëŠ” ì–¸ì–´ì™€ ë‚´ìš©ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í›„ì† ì§ˆë¬¸ì„ ì´ì–´ê°€ì„¸ìš”.
        í‚¤ì›Œë“œëŠ” ì°¸ê³ ì‚¬í•­ì¼ ë¿, ë¬´ì¡°ê±´ ì–¸ê¸‰í•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤.
        """
        
        return base_prompt + personalization
    
    def generate_opening_question(self, profile: InterviewProfile) -> str:
        """ê°œì¸í™”ëœ ì˜¤í”„ë‹ ì§ˆë¬¸ ìƒì„± - ë‚œì´ë„ë³„ ì¡°ì ˆ"""
        institution = profile.institution
        interview_type_kr = {
            "gifted_center": "ì˜ì¬êµìœ¡ì›",
            "science_high": "ê³¼í•™ê³ ",
            "university": "ëŒ€í•™êµ"
        }.get(profile.type, "êµìœ¡ê¸°ê´€")
        
        # ë‚œì´ë„ë³„ ì¸ì‚¬ë§ê³¼ ì§ˆë¬¸ ìŠ¤íƒ€ì¼ ì¡°ì ˆ
        difficulty = profile.difficulty or "high"
        
        if difficulty == "elementary":
            greeting = f"ì•ˆë…•! {institution} {interview_type_kr} ë©´ì ‘ì— ì™€ì¤˜ì„œ ê³ ë§ˆì›Œìš”. ğŸ˜Š"
            comfort = "ê¸´ì¥í•˜ì§€ ë§ê³  í‰ì†Œì²˜ëŸ¼ í¸í•˜ê²Œ ì´ì•¼ê¸°í•´ì£¼ë©´ ë¼ìš”."
            question = f"ë¨¼ì € ìê¸°ì†Œê°œë¥¼ í•´ë³¼ê¹Œìš”? ì´ë¦„ì´ë‘ ëª‡ í•™ë…„ì¸ì§€, ê·¸ë¦¬ê³  {institution}ì— ì™œ ê´€ì‹¬ì´ ìƒê²¼ëŠ”ì§€ ì¬ë¯¸ìˆê²Œ ë“¤ë ¤ì£¼ì„¸ìš”!"
        elif difficulty == "middle":
            greeting = f"ì•ˆë…•í•˜ì„¸ìš”! {institution} {interview_type_kr} ë©´ì ‘ì— ì°¸ì—¬í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."
            comfort = "í¸ì•ˆí•œ ë§ˆìŒìœ¼ë¡œ ìì‹ ì˜ ìƒê°ì„ í‘œí˜„í•´ì£¼ì„¸ìš”."
            question = f"ë¨¼ì € ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì‹œê² ì–´ìš”? ì´ë¦„, í•™ë…„, ê·¸ë¦¬ê³  {institution}ì— ì§€ì›í•˜ê²Œ ëœ ê³„ê¸°ë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”."
        else:  # high, professional, public
            greeting = f"ì•ˆë…•í•˜ì„¸ìš”! {institution} {interview_type_kr} ë©´ì ‘ì— ì°¸ì—¬í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."
            comfort = "ê¸´ì¥í•˜ì§€ ë§ˆì‹œê³  í¸ì•ˆí•˜ê²Œ ìì‹ ì„ í‘œí˜„í•´ì£¼ì„¸ìš”. ë©´ì ‘ê´€ìœ¼ë¡œì„œ ì—¬ëŸ¬ë¶„ì˜ ì ì¬ë ¥ê³¼ ê°€ëŠ¥ì„±ì„ ë°œê²¬í•˜ëŠ” ê²ƒì´ ì œ ëª©í‘œì…ë‹ˆë‹¤."
            question = f"ë¨¼ì € ê°„ë‹¨í•˜ê²Œ ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì‹œê² ì–´ìš”? ì´ë¦„, í˜„ì¬ ìƒí™©, ê·¸ë¦¬ê³  {institution}ì— ê´€ì‹¬ì„ ê°–ê²Œ ëœ íŠ¹ë³„í•œ ê³„ê¸°ê°€ ìˆë‹¤ë©´ í•¨ê»˜ ë§ì”€í•´ì£¼ì„¸ìš”."
        
        return f"""{greeting} 

{comfort}

{question}"""

class InterviewOrchestrator:
    """ë©´ì ‘ ì§„í–‰ ì´ê´„ ê´€ë¦¬ì - Gemini 1.5 Pro ìµœì í™”"""
    
    def __init__(self):
        self.personalized_prompt_manager = PersonalizedPromptManager()
        self.sessions: Dict[str, InterviewSession] = {}
        self.profiles: Dict[str, InterviewProfile] = {}
        
        # Gemini API ì´ˆê¸°í™”
        google_api_key = os.getenv('GOOGLE_API_KEY')
        if not google_api_key:
            print("ê²½ê³ : GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return
            
        genai.configure(api_key=google_api_key)
        
        # Gemini ëª¨ë¸ ì„¤ì •
        self.model = genai.GenerativeModel(
            model_name="gemini-1.5-pro",
            generation_config={
                "temperature": 0.7,
                "top_p": 0.8,
                "top_k": 40,
                "max_output_tokens": 1000,
            }
        )
        
        print("âœ… Gemini 1.5 Pro ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def save_profile(self, profile_id: str, profile: InterviewProfile):
        """í”„ë¡œí•„ ì €ì¥"""
        self.profiles[profile_id] = profile
        print(f"í”„ë¡œí•„ ì €ì¥ë¨: {profile_id} - {profile.institution}")
    
    def get_profile(self, profile_id: str) -> Optional[InterviewProfile]:
        """í”„ë¡œí•„ ì¡°íšŒ"""
        return self.profiles.get(profile_id)
    
    async def start_personalized_interview(self, session_id: str, user_id: str, 
                                         profile: InterviewProfile) -> str:
        """ê°œì¸í™”ëœ ë©´ì ‘ ì‹œì‘ - Gemini Chat Session í™œìš©"""
        
        # Gemini Chat Session ì‹œì‘ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” ë‚˜ì¤‘ì— ì „ì†¡)
        chat = self.model.start_chat(history=[])
        
        session = InterviewSession(
            session_id=session_id,
            user_id=user_id,
            interview_type=profile.type,
            personalized_profile=profile.model_dump(),
            gemini_chat=chat
        )
        self.sessions[session_id] = session
        
        # ê°œì¸í™”ëœ ì˜¤í”„ë‹ ì§ˆë¬¸ ìƒì„± (ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©)
        opening_question = self.personalized_prompt_manager.generate_opening_question(profile)
        
        # ì˜¤í”„ë‹ ì§ˆë¬¸ì„ ëŒ€í™” ì´ë ¥ì— ì¶”ê°€
        session.conversation_history.append({
            "role": "assistant",
            "content": opening_question,
            "timestamp": datetime.now().isoformat()
        })
        
        print(f"âœ… ê°œì¸í™”ëœ ë©´ì ‘ ì‹œì‘: {session_id} - {profile.institution}")
        print(f"ì˜¤í”„ë‹ ì§ˆë¬¸: {opening_question[:100]}...")
        return opening_question
    
    async def process_response(self, session_id: str, user_response: str) -> str:
        """ì‚¬ìš©ì ì‘ë‹µ ì²˜ë¦¬ ë° ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± - Gemini ë©€í‹°í„´ ëŒ€í™”"""
        session = self.sessions.get(session_id)
        if not session:
            return "âŒ ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë©´ì ‘ì„ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”."
        
        try:
            # ì‚¬ìš©ì ì‘ë‹µì„ ì´ë ¥ì— ì¶”ê°€
            session.conversation_history.append({
                "role": "user",
                "content": user_response,
                "timestamp": datetime.now().isoformat()
            })
            
            # Gemini Chat Sessionì„ í†µí•´ ì‘ë‹µ ìƒì„±
            if not session.gemini_chat:
                return "âŒ ë©´ì ‘ ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë©´ì ‘ì„ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”."
            
            # ì²« ë²ˆì§¸ ì‚¬ìš©ì ì‘ë‹µì¸ ê²½ìš°: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ í•¨ê»˜ ëŒ€í™” ì‹œì‘
            if len(session.conversation_history) == 2:  # ì˜¤í”„ë‹ ì§ˆë¬¸ + ì²« ë²ˆì§¸ ì‚¬ìš©ì ì‘ë‹µ
                # ê°œì¸í™”ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
                profile = InterviewProfile(**session.personalized_profile)
                system_prompt = self.personalized_prompt_manager.generate_personalized_system_prompt(profile)
                
                # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ì²« ë²ˆì§¸ ì‘ë‹µì„ í•¨ê»˜ ì „ì†¡
                gemini_response = session.gemini_chat.send_message(
                    f"[ì‹œìŠ¤í…œ] {system_prompt}\n\n[ì§€ì›ì ì²« ë²ˆì§¸ ë‹µë³€] {user_response}\n\nìœ„ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ í›„ì† ì§ˆë¬¸ì´ë‚˜ í”¼ë“œë°±ì„ í•´ì£¼ì„¸ìš”. ê°œì¸í™”ëœ ì •ë³´ë¥¼ ê³ ë ¤í•˜ì—¬ ë©´ì ‘ì„ ì´ì–´ê°€ì£¼ì„¸ìš”."
                )
            else:
                # ì¼ë°˜ì ì¸ í›„ì† ì‘ë‹µ
                gemini_response = session.gemini_chat.send_message(
                    f"[ì§€ì›ì ë‹µë³€] {user_response}\n\nìœ„ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ í›„ì† ì§ˆë¬¸ì´ë‚˜ í”¼ë“œë°±ì„ í•´ì£¼ì„¸ìš”. ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë©´ì ‘ì„ ì´ì–´ê°€ì£¼ì„¸ìš”."
                )
            
            next_question = gemini_response.text.strip()
            
            # AI ì‘ë‹µì„ ëŒ€í™” ì´ë ¥ì— ì¶”ê°€
            session.conversation_history.append({
                "role": "assistant",
                "content": next_question,
                "timestamp": datetime.now().isoformat()
            })
            
            print(f"âœ… ë©´ì ‘ ëŒ€í™” ì§„í–‰: {session_id} - {len(session.conversation_history)}ë²ˆì§¸ êµí™˜")
            return next_question
            
        except Exception as e:
            print(f"âŒ Gemini API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return self._get_fallback_question(session)
    
    def _get_fallback_question(self, session: InterviewSession) -> str:
        """Gemini API ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê¸°ë³¸ ì§ˆë¬¸"""
        fallback_questions = [
            "ì¢€ ë” êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ë“¤ì–´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?",
            "ê·¸ ê²½í—˜ì—ì„œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ë°°ìš´ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì•ìœ¼ë¡œì˜ ê³„íšì´ë‚˜ ëª©í‘œì— ëŒ€í•´ ë§ì”€í•´ì£¼ì„¸ìš”.",
            "ë§ˆì§€ë§‰ìœ¼ë¡œ í•˜ê³  ì‹¶ì€ ë§ì”€ì´ ìˆë‹¤ë©´ ììœ ë¡­ê²Œ í•´ì£¼ì„¸ìš”."
        ]
        
        conversation_count = len([msg for msg in session.conversation_history if msg["role"] == "user"])
        if conversation_count < len(fallback_questions):
            return fallback_questions[conversation_count - 1]
        else:
            return fallback_questions[-1]
    
    async def end_interview(self, session_id: str) -> Dict:
        """ë©´ì ‘ ì¢…ë£Œ ë° ê²°ê³¼ ë¶„ì„"""
        session = self.sessions.get(session_id)
        if not session:
            return {"error": "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        try:
            # Geminië¥¼ í™œìš©í•œ ë©´ì ‘ ë¶„ì„ ë° í”¼ë“œë°± ìƒì„±
            if session.gemini_chat:
                conversation_summary = self._format_conversation_for_analysis(session.conversation_history)
                
                analysis_prompt = f"""
                ë‹¤ìŒì€ ë°©ê¸ˆ ì§„í–‰ëœ ë©´ì ‘ì˜ ì „ì²´ ëŒ€í™”ì…ë‹ˆë‹¤:
                
                {conversation_summary}
                
                ì´ ë©´ì ‘ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
                
                **ë©´ì ‘ ë¶„ì„ ê²°ê³¼**
                1. **ë‹µë³€ í’ˆì§ˆ**: ì „ë°˜ì ì¸ ë‹µë³€ì˜ êµ¬ì²´ì„±ê³¼ ì„±ì˜
                2. **ì „ê³µ ì í•©ì„±**: ì§€ì› ë¶„ì•¼ì— ëŒ€í•œ ì´í•´ë„ì™€ ì—´ì •
                3. **ì„±ì¥ ê°€ëŠ¥ì„±**: ì ì¬ë ¥ê³¼ ë°œì „ ê°€ëŠ¥ì„±
                4. **ê°œì„  ì œì•ˆ**: í–¥í›„ ë©´ì ‘ì´ë‚˜ ì¤€ë¹„ ì‹œ ê³ ë ¤ì‚¬í•­
                5. **ì´í‰**: í•œì¤„ ìš”ì•½
                
                ê°ê´€ì ì´ê³  ê±´ì„¤ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.
                """
                
                analysis_response = session.gemini_chat.send_message(analysis_prompt)
                ai_feedback = analysis_response.text.strip()
            else:
                ai_feedback = "ë©´ì ‘ ì„¸ì…˜ì— ë¬¸ì œê°€ ìˆì–´ AI ë¶„ì„ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        except Exception as e:
            print(f"AI í”¼ë“œë°± ìƒì„± ì˜¤ë¥˜: {e}")
            ai_feedback = "AI í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        
        # ë©´ì ‘ ê²°ê³¼ ë¶„ì„
        analysis = {
            "session_id": session_id,
            "interview_type": session.interview_type,
            "institution": session.personalized_profile.get("institution", "ë¯¸ìƒ") if session.personalized_profile else "ë¯¸ìƒ",
            "duration_minutes": (datetime.now() - session.created_at).seconds // 60,
            "total_exchanges": len([msg for msg in session.conversation_history if msg["role"] == "user"]),
            "conversation_log": session.conversation_history,
            "ai_feedback": ai_feedback,
            "basic_feedback": self._generate_basic_feedback(session)
        }
        
        # ì„¸ì…˜ ì •ë¦¬
        del self.sessions[session_id]
        print(f"âœ… ë©´ì ‘ ì¢…ë£Œ: {session_id}")
        
        return analysis
    
    def _format_conversation_for_analysis(self, conversation_history: List[Dict]) -> str:
        """ëŒ€í™” ì´ë ¥ì„ ë¶„ì„ìš©ìœ¼ë¡œ í¬ë§·íŒ…"""
        formatted_conversation = []
        for msg in conversation_history:
            role = "ë©´ì ‘ê´€" if msg["role"] == "assistant" else "ì§€ì›ì"
            content = msg["content"]
            formatted_conversation.append(f"{role}: {content}")
        
        return "\n\n".join(formatted_conversation)
    
    def _generate_basic_feedback(self, session: InterviewSession) -> str:
        """ê¸°ë³¸ í”¼ë“œë°± ìƒì„±"""
        total_responses = len([msg for msg in session.conversation_history if msg["role"] == "user"])
        
        if total_responses >= 5:
            return "ë©´ì ‘ì— ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬í•´ì£¼ì…¨ìŠµë‹ˆë‹¤. ë‹µë³€ì´ êµ¬ì²´ì ì´ê³  ì„±ì˜ìˆê²Œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
        elif total_responses >= 3:
            return "ë©´ì ‘ì— ì°¸ì—¬í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ê²½í—˜ì„ ê³µìœ í•´ì£¼ì‹œë©´ ë” ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤."
        else:
            return "ë” êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ë‹µë³€ì„ í†µí•´ ìì‹ ì„ ì–´í•„í•´ë³´ì„¸ìš”."

# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_personalized_interview():
    """ê°œì¸í™”ëœ ë©´ì ‘ í…ŒìŠ¤íŠ¸"""
    orchestrator = InterviewOrchestrator()
    
    # í…ŒìŠ¤íŠ¸ìš© í”„ë¡œí•„ ìƒì„±
    test_profile = InterviewProfile(
        type="university",
        institution="ì„œìš¸ëŒ€í•™êµ ê³µê³¼ëŒ€í•™",
        fields=["ì»´í“¨í„°ê³¼í•™", "ì¸ê³µì§€ëŠ¥"],
        keywords=["ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "í”„ë¡œê·¸ë˜ë°"],
        additionalStyle="ë…¼ë¦¬ì ì´ê³  ì²´ê³„ì ì¸ ì§ˆë¬¸ì„ ì„ í˜¸í•©ë‹ˆë‹¤."
    )
    
    # ë©´ì ‘ ì‹œì‘
    session_id = "test_session_001"
    opening = await orchestrator.start_personalized_interview(
        session_id=session_id,
        user_id="user_123",
        profile=test_profile
    )
    
    print(f"ğŸ¤ ë©´ì ‘ê´€: {opening}")
    
    # í…ŒìŠ¤íŠ¸ ì‘ë‹µë“¤
    test_responses = [
        "ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ê¹€í•™ìƒì…ë‹ˆë‹¤. ê³ ë“±í•™êµ ë•Œë¶€í„° í”„ë¡œê·¸ë˜ë°ì— ê´€ì‹¬ì´ ë§ì•˜ê³ , íŠ¹íˆ AI ê¸°ìˆ ë¡œ ì‚¬íšŒ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì‹¶ì–´ ì„œìš¸ëŒ€ ì»´ê³µê³¼ì— ì§€ì›í–ˆìŠµë‹ˆë‹¤.",
        "ê³ ë“±í•™êµ ë•Œ ì½”ë”© ë™ì•„ë¦¬ì—ì„œ ì±—ë´‡ì„ ë§Œë“¤ì–´ë´¤ëŠ”ë°, ê·¸ ê²½í—˜ì´ AIì— ëŒ€í•œ ê´€ì‹¬ì„ ë”ìš± í‚¤ì› ìŠµë‹ˆë‹¤. ë‹¨ìˆœí•œ ê·œì¹™ ê¸°ë°˜ ì±—ë´‡ì´ì—ˆì§€ë§Œ, ì‚¬ìš©ìì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ëª¨ìŠµì´ ì‹ ê¸°í–ˆì–´ìš”.",
        "ëŒ€í•™ì—ì„œëŠ” ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì„ ê¹Šì´ ê³µë¶€í•˜ê³ , ì‹¤ì œ ë¬¸ì œì— ì ìš©í•´ë³´ëŠ” í”„ë¡œì íŠ¸ë¥¼ ë§ì´ í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. íŠ¹íˆ ì˜ë£Œ ë¶„ì•¼ì— AIë¥¼ ì ìš©í•˜ëŠ” ì—°êµ¬ì— ê´€ì‹¬ì´ ìˆì–´ìš”."
    ]
    
    for i, response in enumerate(test_responses, 1):
        print(f"\nğŸ‘¤ ì§€ì›ì: {response}")
        next_question = await orchestrator.process_response(session_id, response)
        print(f"ğŸ¤ ë©´ì ‘ê´€: {next_question}")
    
    # ë©´ì ‘ ì¢…ë£Œ
    print("\n" + "="*50)
    result = await orchestrator.end_interview(session_id)
    print("ğŸ“‹ ë©´ì ‘ ë¶„ì„ ê²°ê³¼:")
    print(f"- ì´ êµí™˜ íšŸìˆ˜: {result['total_exchanges']}")
    print(f"- ë©´ì ‘ ì‹œê°„: {result['duration_minutes']}ë¶„")
    print(f"- AI í”¼ë“œë°±:\n{result['ai_feedback']}")

if __name__ == "__main__":
    print("ğŸš€ AI ë©´ì ‘ ì‹œìŠ¤í…œ (Gemini 1.5 Pro) ì‹œì‘...")
    asyncio.run(test_personalized_interview()) 